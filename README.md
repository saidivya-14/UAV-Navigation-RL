# ğŸš€ UAV Navigation using Deep Reinforcement Learning

## ğŸ“Œ Project Overview
This project implements **autonomous UAV navigation** using **Deep Q-Learning (DQN)**. The UAV learns to navigate a grid-based environment while avoiding obstacles and efficiently reaching a target position.

## ğŸ¯ Features
- ğŸ§  **Deep Q-Network (DQN)** for reinforcement learning.
- ğŸš§ **Obstacle avoidance** using dataset-based obstacle mapping.
- ğŸ¯ **Reward-based training** to optimize UAV movements.
- ğŸ“ˆ **Visualization of training performance** using Matplotlib.
- âš¡ **Efficient training** with experience replay and epsilon decay.

## ğŸ“‚ Project Structure
```
UAV_Navigation_Project/
â”‚-- uav_navigation.py  # Main RL training script
â”‚-- UAV_full_data.csv  # Dataset for obstacle mapping
â”‚-- README.md          # Project documentation
â”‚-- requirements.txt   # Dependencies

```

## ğŸ› ï¸ Installation & Setup
1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/UAV-Navigation-RL.git
   cd UAV-Navigation-RL
   ```
2. **Create a virtual environment (optional but recommended):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use: venv\Scripts\activate
   ```
3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸƒâ€â™‚ï¸ Running the Project
To train the UAV agent, run the following command:
```bash
python uav_navigation.py
```

## ğŸ“Š Training Performance Visualization
After training, a **reward plot** is generated showing how the UAV's performance improves across episodes.

### Example Output:
```
âœ… Episode 10: Total Reward = -20500
âœ… Episode 20: Total Reward = -14500
âœ… Episode 30: Total Reward = -9000
âœ… Episode 40: Total Reward = -3500
âœ… Episode 50: Total Reward = 1000 (UAV successfully reaches the target!)
```

### Example Reward Plot:
![Training Progress][(https://via.placeholder.com/800x400?text=Training+Reward+Plot](https://github.com/saidivya-14/UAV-Navigation-RL/blob/main/UAV_output.jpg))  
*(Replace the placeholder with the actual generated plot)*

## ğŸ”® Future Enhancements
- âœ… Add **dynamic obstacles** for real-time UAV navigation challenges.
- âœ… Extend navigation to **3D space** with altitude control.
- âœ… Integrate with UAV simulation frameworks like **AirSim** or **Gazebo**.
- âœ… Implement **multi-agent UAV coordination** strategies.

## ğŸ“„ Requirements
The project requires the following Python libraries:
- numpy
- tensorflow
- keras
- matplotlib
- pandas

Install them using:
```bash
pip install -r requirements.txt
```

## ğŸ¤ Contributing
We welcome contributions! Feel free to fork the repository, make changes, and submit a pull request. For major changes, open an issue first to discuss what you'd like to improve.

## ğŸ“œ License
This project is licensed under the **MIT License**. See the `LICENSE` file for details.

---

### ğŸ”— Connect with Me
ğŸ’¼ **LinkedIn:** [Your Profile](www.linkedin.com/in/saidivya-kodipaka)  
ğŸ“‚ **GitHub:** [Your Repos]([https://github.com/your-username](https://github.com/saidivya-14))  
ğŸ“§ **Email:** saidivyakodipaka856@gmail.com

